Project: config_transformer
experiment: ex6
architecture:
  block_size: 512
  vocab_size: 3000
  n_layer: 12
  n_head: 12
  n_embd: 1080
  dropout: 0.0
  bias: true
data:
  PATH:
    main_vol: /journel/s0/zur74/data/new_energy_well/train_vol/main_vol
    sub_vol: /journel/s0/zur74/data/new_energy_well/train_vol/sub_vol
  ct_idx:
  - 2
  - 3
  - 4
  - 5
checkpoints:
  PATH: /journel/s0/zur74/LatentPoreUpscale3DNet/lpu3dnet/train/checkpoints
train:
  epochs: 300
  batch_size: 20
  learning_rate: 0.0005
  betas:
  - 0.99
  - 0.999
  weight_decay: 0.8
