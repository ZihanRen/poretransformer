Project: pretrained

# which model to read from which experiment?
experiment: ex1
epoch: 120

pretrained_codebook:
  path: '/journel/s0/zur74/LatentPoreUpscale3DNet/lpu3dnet/finetune/kmeans_6000.pkl'


usecodebook_ema: false  # Set to true to use Codebook_EMA

architecture:
  encoder:
    img_channels: 1
    latent_dim: 256
    num_res_blocks: 2
    num_groups: 16
    # reduce from 64->2: 64/(2^5) = 2
    # if you want to have a codebook size of 4^3, reduce to 256  
    channels: [16,16,64,128,256,512]
  
  codebook:
    # codebook size
    size: 3000
    # codebook dimension
    latent_dim: 256
    # weight of commitment loss for z_n (embedding)
    beta_c: 0.8
    autoencoder: true # whether to use autoencoder to replace genereator boolean
    legacy: false # whether to use legacy codebook boolean

  codebookEMA:
    # codebook size
    size: 3000
    # codebook dimension
    latent_dim: 256
    # weight of commitment loss for z_n (embedding)
    beta_c: 1 
    decay: 0.9 # whether to use autoencoder to replace genereator boolean

  decoder:
    img_channels: 1
    latent_dim: 256
    num_res_blocks: 3
    num_groups: 16
    # 2->4->8->16->32->64 (no upsampling for last layer & first layer)
    channels: [512, 256, 128, 128, 64, 16, 16]

  discriminator:
    img_channels: 1
    init_filters_num: 64
    num_layers: 3

# path of data and checkpoints
data:
  PATH:
    main_vol: /journel/s0/zur74/data/new_energy_well/train_vol/main_vol
    sub_vol: /journel/s0/zur74/data/new_energy_well/train_vol/sub_vol
  ct_idx: [2,3,4,5]

checkpoints:
  PATH: /journel/s0/zur74/LatentPoreUpscale3DNet/lpu3dnet/train/checkpoints
